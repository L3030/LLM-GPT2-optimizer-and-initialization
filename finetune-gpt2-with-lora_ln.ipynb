{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d49acf1-9ad1-4a6c-9312-6785cb3f5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './gpt2' #\"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d835e84-a01d-4c33-926b-60d9dd4a7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54a564f1-f8f3-42a6-b160-bebdbcc3aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-15 16:01:10--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt [following]\n",
      "--2024-04-15 16:01:11--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9624463 (9.2M) [text/plain]\n",
      "Saving to: ‘train.txt.19’\n",
      "\n",
      "train.txt.19        100%[===================>]   9.18M  3.26MB/s    in 2.8s    \n",
      "\n",
      "2024-04-15 16:01:14 (3.26 MB/s) - ‘train.txt.19’ saved [9624463/9624463]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d48464ea-991f-48b2-9166-3323cfd61676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-15 16:01:15--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt [following]\n",
      "--2024-04-15 16:01:15--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1351149 (1.3M) [text/plain]\n",
      "Saving to: ‘test.txt.19’\n",
      "\n",
      "test.txt.19         100%[===================>]   1.29M  2.71MB/s    in 0.5s    \n",
      "\n",
      "2024-04-15 16:01:16 (2.71 MB/s) - ‘test.txt.19’ saved [1351149/1351149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6e60596-028f-4c4b-a95d-f74a0ff3b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : The Vaults | Type : pub | price : more than £ 30 | customer rating : 5 out of 5 | near : Café Adriatic||The Vaults pub near Café Adriatic has a 5 star rating . Prices start at £ 30 . \n",
      "name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Café Brazil||Close to Café Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of £ 10.50 . Delicious Pub food . \n",
      "name : The Eagle | Type : coffee shop | food : Japanese | price : less than £ 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King||The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than £ 20 for Japanese food . \n",
      "name : The Mill | Type : coffee shop | food : French | price : £ 20 - 25 | area : riverside | near : The Sorrento||Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at £ 20- £ 25 it is in the riverside area . \n",
      "name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat||For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat . \n"
     ]
    }
   ],
   "source": [
    "!head -n 5 train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5fabe-590c-459b-aa16-4b5a506fb54b",
   "metadata": {},
   "source": [
    "Convert above data into JsonL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7376e0c0-16c9-46f4-ad4c-83d1a677f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import json\n",
    "\n",
    "def format_convert(read_file, write_file):\n",
    "    with open(read_file, \"r\", encoding=\"utf8\") as reader, \\\n",
    "    \t open(write_file, \"w\", encoding=\"utf8\") as writer :\n",
    "    \tfor line in reader:\n",
    "    \t\titems = line.strip().split(\"||\")\n",
    "    \t\tcontext = items[0]\n",
    "    \t\tcompletion = items[1].strip(\"\\n\")\n",
    "    \t\tx = {}\n",
    "    \t\tx[\"context\"] = context\n",
    "    \t\tx[\"completion\"] = completion\n",
    "    \t\twriter.write(json.dumps(x)+\"\\n\")\n",
    "\n",
    "format_convert(\"train.txt\", \"train_formatted.jsonl\")\n",
    "format_convert(\"test.txt\", \"test_formatted.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec952-fe03-475f-9f3e-22237cc9c44b",
   "metadata": {},
   "source": [
    "Show the converted data (first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb32aca7-bd0e-4847-a4c2-cc7e67dc2b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"context\": \"name : The Vaults | Type : pub | price : more than \\u00a3 30 | customer rating : 5 out of 5 | near : Caf\\u00e9 Adriatic\", \"completion\": \"The Vaults pub near Caf\\u00e9 Adriatic has a 5 star rating . Prices start at \\u00a3 30 .\"}\n",
      "\n",
      "{\"context\": \"name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Caf\\u00e9 Brazil\", \"completion\": \"Close to Caf\\u00e9 Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of \\u00a3 10.50 . Delicious Pub food .\"}\n",
      "\n",
      "{\"context\": \"name : The Eagle | Type : coffee shop | food : Japanese | price : less than \\u00a3 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King\", \"completion\": \"The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than \\u00a3 20 for Japanese food .\"}\n",
      "\n",
      "{\"context\": \"name : The Mill | Type : coffee shop | food : French | price : \\u00a3 20 - 25 | area : riverside | near : The Sorrento\", \"completion\": \"Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at \\u00a3 20- \\u00a3 25 it is in the riverside area .\"}\n",
      "\n",
      "{\"context\": \"name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat\", \"completion\": \"For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat .\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_formatted.jsonl\", \"r\") as reader:\n",
    "    for _ in range(5):\n",
    "        print(next(reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5433dc0-b5a5-4c01-adb5-3ffa2279eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    fast_tokenizer=True)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5f250929-5703-4b17-9f7b-26340950c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of tokens is 1024 in this model.\n",
      "But here we use max 512 tokens in the training.\n"
     ]
    }
   ],
   "source": [
    "block_size = 512\n",
    "\n",
    "print(f\"Max length of tokens is {tokenizer.model_max_length} in this model.\")\n",
    "print(f\"But here we use max {block_size} tokens in the training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f2f38aa-b3d0-4614-aa59-8ddd977176d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "def fill_ignore_label(l, c):\n",
    "    l[:len(c) - 1] = [-100] * (len(c) - 1)\n",
    "    return l\n",
    "\n",
    "def pad_tokens(tokens, max_seq_length, padding_token):\n",
    "    res_tokens = tokens[:max_seq_length]\n",
    "    token_len = len(res_tokens)\n",
    "    res_tokens = res_tokens + \\\n",
    "        [padding_token for _ in range(max_seq_length - token_len)]\n",
    "    return res_tokens\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # tokenize both context and completion respectively\n",
    "    # (context and completion is delimited by \"\\n\")\n",
    "    context_list = list(zip(*batch))[0]\n",
    "    context_list = [c + \"\\n\" for c in context_list]\n",
    "    completion_list = list(zip(*batch))[1]\n",
    "    context_result = tokenizer(context_list)\n",
    "    context_tokens = context_result[\"input_ids\"]\n",
    "    context_masks = context_result[\"attention_mask\"]\n",
    "    completion_result = tokenizer(completion_list)\n",
    "    completion_tokens = completion_result[\"input_ids\"]\n",
    "    completion_masks = completion_result[\"attention_mask\"]\n",
    "    # concatenate token\n",
    "    inputs = [i + j for i, j in zip(context_tokens, completion_tokens)]\n",
    "    masks = [i + j for i, j in zip(context_masks, completion_masks)]\n",
    "    # create label\n",
    "    eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "    labels = [t[1:] + [eos_id] for t in inputs]\n",
    "    labels = list(map(fill_ignore_label, labels, context_tokens))\n",
    "    # truncate and pad tokens\n",
    "    inputs = [pad_tokens(t, block_size, 0) for t in inputs] # OPT and GPT-2 doesn't use pad token (instead attn mask is used)\n",
    "    masks = [pad_tokens(t, block_size, 0) for t in masks]\n",
    "    labels = [pad_tokens(t, block_size, -100) for t in labels]\n",
    "    # convert to tensor\n",
    "    inputs = torch.tensor(inputs, dtype=torch.int64).to(device)\n",
    "    masks = torch.tensor(masks, dtype=torch.int64).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "    # print(labels.shape)\n",
    "    return inputs, labels, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084d2e9-ef64-47a2-aec9-d24ead1cb38a",
   "metadata": {},
   "source": [
    "Now create PyTorch dataloader with previous function (collator function).\n",
    "\n",
    "> Note : In this example, data is small and we then load all JSON data in memory.<br>\n",
    "> When it's large, load data progressively by implementing custom PyTorch dataset. (See [here](https://github.com/tsmatz/decision-transformer) for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3bce3bb-2215-4bd6-a6a6-5b6b9d5afdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gradient_accumulation_steps = 16\n",
    "\n",
    "data = pd.read_json(\"train_formatted.jsonl\", lines=True)\n",
    "dataloader = DataLoader(\n",
    "    list(zip(data[\"context\"], data[\"completion\"])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba64144-b698-457e-b827-941020456536",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd360d-7bdc-4fd7-9b12-bcf9fe0a8db2",
   "metadata": {},
   "source": [
    "Load model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "271181bd-677a-4da9-9e57-2874f5e47bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    ").to(device)\n",
    "\n",
    "# num_hidden_layers = config.n_layer\n",
    "# parameters_to_finetuned = []\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'h.' + str(num_hidden_layers - 2) in name or 'h.' + str(num_hidden_layers - 1) in name:\n",
    "#         parameters_to_finetuned.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "51a0c4fc-e0a7-4bbf-b25a-c335fe61f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input, mask, eos_id, pred_sequence_length):\n",
    "    predicted_last_id = -1\n",
    "    start_token_len = torch.sum(mask).cpu().numpy()\n",
    "    token_len = start_token_len\n",
    "    with torch.no_grad():\n",
    "        while (predicted_last_id != eos_id) and \\\n",
    "              (token_len - start_token_len < pred_sequence_length):\n",
    "            output = model(\n",
    "                input_ids=input,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            predicted_ids = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "            predicted_last_id = predicted_ids[0][token_len - 1]\n",
    "            input[0][token_len] = predicted_last_id\n",
    "            mask[0][token_len] = 1\n",
    "            token_len = torch.sum(mask).cpu().numpy()\n",
    "    return input, token_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28b7e13f-e8fb-4a9f-90ed-0464463ef569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, the world was a place of great beauty and great danger. The world was\n",
      "My name is Clara and I am a woman. I am a woman who is a woman. I am a\n"
     ]
    }
   ],
   "source": [
    "eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "\n",
    "result = tokenizer(\"Once upon a time,\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))\n",
    "\n",
    "result = tokenizer(\"My name is Clara and I am\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "495728ef-fbe6-4953-a354-4b7a8bb88798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "name : The Cricketers | Type : restaurant | food : Chinese | price : moderate | customer rating : 1 out of 5 | area : riverside | family friendly : no | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "name : The Cricketers | Type : restaurant | food : Chinese | price : moderate | customer rating : 1 out of 5 | area : riverside | family friendly : no | near : All Bar One\n",
      "\n",
      "The Cricketers | Type : restaurant | food : Chinese | price : moderate | customer rating : 1 out of 5 | area : riverside\n",
      "********** input **********\n",
      "name : The Wrestlers | Type : restaurant | food : Japanese | price : more than £ 30 | area : city centre | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Wrestlers | Type : restaurant | food : Japanese | price : more than £ 30 | area : city centre | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "The restaurant is located in the centre of the city centre. It is a small restaurant with a small menu. The menu is very good and the\n",
      "********** input **********\n",
      "name : The Vaults | Type : pub | food : Japanese | price : less than £ 20 | customer rating : low | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Vaults | Type : pub | food : Japanese | price : less than £ 20 | customer rating : low | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "The following restaurants are available in the city centre:\n",
      "\n",
      "The following restaurants are available in the city centre:\n",
      "\n",
      "The following restaurants are available\n",
      "********** input **********\n",
      "name : The Phoenix | Type : pub | food : Fast food | price : moderate | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Phoenix | Type : pub | food : Fast food | price : moderate | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      ": The Phoenix | Type : pub | food : Fast food | price : moderate | area : riverside | family friendly : no | near :\n",
      "********** input **********\n",
      "name : The Cricketers | Type : coffee shop | customer rating : high | family friendly : yes | near : Express by Holiday Inn\n",
      "\n",
      "********** result **********\n",
      "name : The Cricketers | Type : coffee shop | customer rating : high | family friendly : yes | near : Express by Holiday Inn\n",
      "\n",
      "The Cricketers | Type : coffee shop | customer rating : high | family friendly : yes | near : Express by Holiday Inn\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5acb8f62-791a-4fa4-b00c-2666cf34827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "06f50179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType\n",
    "from peft import PeftModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77889272-9a93-491b-93cb-b0bed5ce7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "class LoRA_Linear(nn.Module):\n",
    "    def __init__(self, weight, bias, lora_dim): #lora_dim = r = 4?\n",
    "        super(LoRA_Linear, self).__init__()\n",
    "\n",
    "        row, column = weight.shape\n",
    "        # row, column = weight.size(0)\n",
    "\n",
    "        # restore Linear\n",
    "        if bias is None:\n",
    "            self.linear = nn.Linear(column, row, bias=False)\n",
    "            self.linear.load_state_dict({\"weight\": weight})\n",
    "        else:\n",
    "            self.linear = nn.Linear(column, row)\n",
    "            self.linear.load_state_dict({\"weight\": weight, \"bias\": bias}) #self.weight = orginal weights\n",
    "\n",
    "        # create LoRA weights (with initialization)\n",
    "        self.lora_right = nn.Parameter(torch.zeros(column, lora_dim))\n",
    "        nn.init.kaiming_uniform_(self.lora_right, a=math.sqrt(5))\n",
    "        self.lora_left = nn.Parameter(torch.zeros(lora_dim, row))\n",
    "\n",
    "\n",
    "    # input.shape == [8, 512, 768] batch_size, latent_dim, embedding_size\n",
    "    def forward(self, input):\n",
    "        print(\"input shape:\", input.shape)\n",
    "        print(self.linear)\n",
    "        x = self.linear(input)\n",
    "        print(x.shape)\n",
    "        print(self.lora_right.shape)\n",
    "        print(self.lora_left.shape)\n",
    "        assert 1==0\n",
    "        y = input @ self.lora_right @ self.lora_left\n",
    "        print('output:',(x+y).shape)\n",
    "        assert 1==0\n",
    "        return x + y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cfe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "class LoRA_Linear(nn.Module):\n",
    "    def __init__(self, weight, bias, lora_dim): #lora_dim = r = 4?\n",
    "        super(LoRA_Linear, self).__init__()\n",
    "\n",
    "        row, column = weight.shape\n",
    "        # row, column = weight.size(0)\n",
    "\n",
    "        # restore Linear\n",
    "        if bias is None:\n",
    "            self.linear = nn.Linear(column, row, bias=False)\n",
    "            self.linear.load_state_dict({\"weight\": weight})\n",
    "        else:\n",
    "            self.linear = nn.Linear(column, row)\n",
    "            self.linear.load_state_dict({\"weight\": weight, \"bias\": bias}) #self.weight = orginal weights\n",
    "\n",
    "        # create LoRA weights (with initialization)\n",
    "        self.lora_right = nn.Parameter(torch.zeros(column, lora_dim))\n",
    "        nn.init.kaiming_uniform_(self.lora_right, a=math.sqrt(5))\n",
    "        self.lora_left = nn.Parameter(torch.zeros(lora_dim, row))\n",
    "\n",
    "\n",
    "    # input.shape == [8, 512, 768] batch_size, latent_dim, embedding_size\n",
    "    def forward(self, input):\n",
    "        print(\"input shape:\", input.shape)\n",
    "        print(self.linear)\n",
    "        x = self.linear(input)\n",
    "        print(x.shape)\n",
    "        print(self.lora_right.shape)\n",
    "        print(self.lora_left.shape)\n",
    "        assert 1==0\n",
    "        y = input @ self.lora_right @ self.lora_left\n",
    "        print('output:',(x+y).shape)\n",
    "        assert 1==0\n",
    "        return x + y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "baf8a748-a3e3-45b8-9c64-252c56abe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_dim = 128\n",
    "\n",
    "# get target module name\n",
    "target_names = []\n",
    "target_modules = []\n",
    "# layer_tobe_finetuned = model.\n",
    "for name, module in model.named_modules():\n",
    "    # print(name)\n",
    "    if \"transformer.h.10\" in name or \"transformer.h.11\" in name:\n",
    "        if \"ln_1\" in name or \"ln_2\" in name: # or \"attn.c\" in name or \"mlp.c\" in name:\n",
    "            target_names.append(name)\n",
    "            target_modules.append(module)\n",
    "\n",
    "\n",
    "# replace each module with LoRA\n",
    "for name in target_names:\n",
    "    name_struct = name.split(\".\")\n",
    "    # get target module\n",
    "    module_list = [model]\n",
    "   \n",
    "    for struct in name_struct:\n",
    "        module_list.append(getattr(module_list[-1], struct))\n",
    "\n",
    "    # build LoRA\n",
    "    lora = LoRA_Linear(\n",
    "        weight = torch.transpose(module_list[-1].weight.unsqueeze(0), 0, 1),\n",
    "        bias = module_list[-1].bias,\n",
    "        lora_dim = lora_dim,\n",
    "    ).to(device)\n",
    "    # replace\n",
    "    module_list[-2].__setattr__(name_struct[-1], lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf16b414-b973-40eb-be81-fd2aa3dde439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-9): 10 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x GPT2Block(\n",
       "        (ln_1): LoRA_Linear(\n",
       "          (linear): Linear(in_features=1, out_features=768, bias=True)\n",
       "        )\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LoRA_Linear(\n",
       "          (linear): Linear(in_features=1, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9099c08-f6a6-45f8-939b-cc3ed9415976",
   "metadata": {},
   "source": [
    "Finally, freeze all parameters except for LoRA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81d06bba-955b-4806-8ff7-f217252e3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora_right\" in name or \"lora_left\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c7d6f-6c50-4839-88a5-c851caab9ba2",
   "metadata": {},
   "source": [
    "## Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb51298a-2d55-466c-a990-0ea08a247350",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=0.0002,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-6,\n",
    ")\n",
    "\n",
    "# from came_pytorch import CAME\n",
    "# optimizer = CAME(\n",
    "#     model.parameters(),\n",
    "#     lr=2e-4,\n",
    "#     weight_decay=1e-2,\n",
    "#     betas=(0.9, 0.999, 0.9999),\n",
    "#     eps=(1e-30, 1e-16)\n",
    "# )\n",
    "\n",
    "# from adafactor import AdaFactor\n",
    "\n",
    "# from adafactor1 import Adafactor\n",
    "# optimizer = Adafactor(model.parameters()) $try lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6f95bdf6-4498-4d40-90aa-1267d55f38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR, LRScheduler, ExponentialLR, CosineAnnealingLR\n",
    "\n",
    "num_epochs = 2\n",
    "num_warmup_steps = 500\n",
    "\n",
    "num_update_steps = math.ceil(len(dataloader) / batch_size / gradient_accumulation_steps)\n",
    "def _get_linear_schedule(current_step):\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    return max(0.0, float(num_update_steps * num_epochs - current_step) / float(max(1, num_update_steps * num_epochs - num_warmup_steps)))\n",
    "\n",
    "# scheduler = LambdaLR(optimizer, lr_lambda=_get_linear_schedule)\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fcc177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_matrix(self, matrix):\n",
    "    file_name = './save/' + '.pkl'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(matrix, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9e828-c4fb-493d-a6de-78e03dbf035e",
   "metadata": {},
   "source": [
    "Run fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3752481d-8ee8-4c43-b677-add136a2fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([8, 512, 768])\n",
      "Linear(in_features=1, out_features=768, bias=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4096x768 and 1x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels, masks) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 13\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m), labels)\n\u001b[1;32m     18\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1075\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1075\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:899\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    889\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    890\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    891\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    896\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    897\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:388\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    378\u001b[0m     hidden_states: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    386\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]]:\n\u001b[1;32m    387\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 388\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m    390\u001b[0m         hidden_states,\n\u001b[1;32m    391\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    396\u001b[0m     )\n\u001b[1;32m    397\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[95], line 29\u001b[0m, in \u001b[0;36mLoRA_Linear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear)\n\u001b[0;32m---> 29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_right\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/wlgpt2/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4096x768 and 1x768)"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "if os.path.exists(\"loss.txt\"):\n",
    "    os.remove(\"loss.txt\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    model.train()\n",
    "    for i, (inputs, labels, masks) in enumerate(dataloader):\n",
    "        with torch.set_grad_enabled(True):\n",
    "           \n",
    "           \n",
    "            outputs = model(\n",
    "                input_ids=inputs,\n",
    "                attention_mask=masks,\n",
    "            )\n",
    "            loss = F.cross_entropy(outputs.logits.transpose(1,2), labels)\n",
    "            loss.backward()\n",
    "            if ((i + 1) % gradient_accumulation_steps == 0) or \\\n",
    "               (i + 1 == len(dataloader)):\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            print(f\"Epoch {epoch+1} {math.ceil((i + 1) / batch_size / gradient_accumulation_steps)}/{num_update_steps} - loss: {loss.item() :2.4f}\", end=\"\\r\")\n",
    "\n",
    "        # record loss\n",
    "        with open(\"loss.txt\", \"a\") as f:\n",
    "            f.write(str(loss.item()))\n",
    "            f.write(\"\\n\")\n",
    "    print(\"\")\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), \"finetuned_gpt2.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83993d92-d7ed-4a07-8985-cc59bd4e4fef",
   "metadata": {},
   "source": [
    "> Note : Here we save LoRA-enabled model without any changes, but you can also merge the trained LoRA's parameters into the original model's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc086e5-e93f-4264-a8fa-6428f844ac3c",
   "metadata": {},
   "source": [
    "Show loss transition in plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c5aee-38d4-4a2a-952c-4fd2bef41e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"loss.txt\")\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29903cae-404e-4209-9c84-6c8a69609c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "name : The Mill | Type : restaurant | food : English | price : less than £ 20 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Mill | Type : restaurant | food : English | price : less than £ 20 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "The Mill is a family - friendly restaurant that serves English food. It is located in the city centre near Raja Indian Cuisine.<|endoftext|>\n",
      "********** input **********\n",
      "name : The Punter | Type : restaurant | food : Indian | price : high | customer rating : 1 out of 5 | area : riverside | family friendly : no | near : Express by Holiday Inn\n",
      "\n",
      "********** result **********\n",
      "name : The Punter | Type : restaurant | food : Indian | price : high | customer rating : 1 out of 5 | area : riverside | family friendly : no | near : Express by Holiday Inn\n",
      "The Punter is a restaurant providing Indian food in the high price range. It is located in the riverside. It is near Express by Holiday Inn\n",
      "********** input **********\n",
      "name : The Phoenix | Type : pub | food : French | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : yes | near : Crowne Plaza Hotel\n",
      "\n",
      "********** result **********\n",
      "name : The Phoenix | Type : pub | food : French | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : yes | near : Crowne Plaza Hotel\n",
      "The Phoenix is a family - friendly pub located near the Crowne Plaza Hotel. It serves cheap French food and has a customer rating of 5 out of\n",
      "********** input **********\n",
      "name : The Plough | Type : pub | food : Chinese | price : high | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Plough | Type : pub | food : Chinese | price : high | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "The Plough is a pub that serves Chinese food. It is located in the city centre near Raja Indian Cuisine. It is child friendly and\n",
      "********** input **********\n",
      "name : The Vaults | Type : restaurant | food : Indian | price : high | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Vaults | Type : restaurant | food : Indian | price : high | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "The Vaults is a high priced restaurant providing Indian food in the high price range. It is located in the city centre. It is near Raja Indian\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c1dd3-4057-497a-83ae-f99b1883697e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
